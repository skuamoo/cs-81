{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import whiten\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load Shakespeare scenes\n",
    "f = open('shakespeare_scenes.txt')\n",
    "shk = f.read()\n",
    "shakespeare_scenes = eval(shk)\n",
    "f.close()\n",
    "\n",
    "#Load Shakespeare acts\n",
    "f = open('shakespeare_acts.txt')\n",
    "shk = f.read()\n",
    "shakespeare_acts = eval(shk)\n",
    "f.close()\n",
    "\n",
    "#Create baseline of all text in all plays\n",
    "all_acts_text = []\n",
    "all_acts_lines = []\n",
    "for act in shakespeare_acts:\n",
    "    all_acts_text.append(act['text'])\n",
    "all_text = ' '.join(all_acts_text)\n",
    "all_lines = ' '.join(all_acts_lines)\n",
    "all_tokens = nltk.word_tokenize(all_text)\n",
    "all_freq = nltk.FreqDist(all_tokens)\n",
    "#Get top 20 most frequent terms across all plays\n",
    "vocabulary = [item[0] for item in sorted(all_freq.items(), key=lambda x: x[1], reverse=True)][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def structural(data):\n",
    "    elements_text = [element['text'] for element in data]\n",
    "    elements_lines = [element['lines'] for element in data]\n",
    "    elements_count = len(data)\n",
    "    \n",
    "    features = np.zeros((elements_count, 11), np.float64)\n",
    "    for i, element in enumerate(elements_lines):\n",
    "        text = ' '.join(element)\n",
    "        lines = element\n",
    "        lines_count = len(lines)\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        sentences = nltk.data.load('tokenizers/punkt/english.pickle').tokenize(text.lower())\n",
    "        sentences_count = len(sentences)\n",
    "        words = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(text.lower())\n",
    "        words_unique = list(set(words))        \n",
    "        words_line_counts = [len(nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(line.lower())) for line in lines]        \n",
    "        words_sent_counts = [len(nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence.lower())) for sentence in sentences]\n",
    "\n",
    "        #Calculate features\n",
    "        mean_word_freq = float(len(words))/float(len(words_unique))\n",
    "        mean_words_line = np.mean(words_line_counts)\n",
    "        std_words_line = np.std(words_line_counts)\n",
    "        mean_words_sent = np.mean(words_sent_counts)\n",
    "        std_words_sent = np.std(words_sent_counts)\n",
    "        mean_commas_line = float(tokens.count(\",\"))/float(lines_count)\n",
    "        mean_commas_sent = float(tokens.count(\",\"))/float(sentences_count)\n",
    "        mean_colons_line = float(tokens.count(\":\"))/float(lines_count)\n",
    "        mean_colons_sent = float(tokens.count(\":\"))/float(sentences_count)\n",
    "        mean_scolons_line = float(tokens.count(\";\"))/float(lines_count)\n",
    "        mean_scolons_sent = float(tokens.count(\";\"))/float(sentences_count)\n",
    "        \n",
    "        #Assign features to matrix\n",
    "        features[i,0] = mean_word_freq\n",
    "        features[i,1] = mean_words_line\n",
    "        features[i,2] = std_words_line\n",
    "        features[i,3] = mean_words_sent\n",
    "        features[i,4] = std_words_sent\n",
    "        features[i,5] = mean_commas_line\n",
    "        features[i,6] = mean_commas_sent\n",
    "        features[i,7] = mean_colons_line\n",
    "        features[i,8] = mean_colons_sent\n",
    "        features[i,9] = mean_scolons_line\n",
    "        features[i,10] = mean_scolons_sent\n",
    "        \n",
    "    #scale features\n",
    "    features = whiten(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_freq(data):\n",
    "    elements_text = [element['text'] for element in data]\n",
    "    elements_lines = [element['lines'] for element in data]\n",
    "    elements_count = len(data)\n",
    "    \n",
    "    vectorizer = CountVectorizer(vocabulary=vocabulary, tokenizer=nltk.word_tokenize)\n",
    "    freq_vec = vectorizer.fit_transform(elements_text).toarray().astype(np.float64)\n",
    "    freq_vec /= np.c_[np.apply_along_axis(np.linalg.norm, 1, freq_vec)]\n",
    " \n",
    "    return freq_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def authorship(data, clusters):\n",
    "    freq = word_freq(data)\n",
    "    struc = structural(data)\n",
    "    km_freq = KMeans(n_clusters=clusters, init='k-means++', n_init=99)\n",
    "    km_struc = KMeans(n_clusters=clusters, init='k-means++', n_init=99)\n",
    "    km_freq.fit(freq)\n",
    "    km_struc.fit(struc)\n",
    "    km_freq_pred = km_freq.predict(freq)\n",
    "    km_struc_pred = km_struc.predict(struc)\n",
    "    km_freq_score = silhouette_score(freq, km_freq_pred, metric='sqeuclidean')\n",
    "    km_struc_score = silhouette_score(struc, km_struc_pred, metric='sqeuclidean')\n",
    "    gmm_freq = GMM(n_components = clusters, covariance_type=\"full\")\n",
    "    gmm_struc = GMM(n_components = clusters, covariance_type=\"full\")\n",
    "    gmm_freq.fit(freq)\n",
    "    gmm_struc.fit(struc)\n",
    "    gmm_freq_pred = km_freq.predict(freq)\n",
    "    gmm_struc_pred = km_struc.predict(struc)\n",
    "    gmm_freq_score = silhouette_score(freq, gmm_freq_pred, metric='sqeuclidean')\n",
    "    gmm_struc_score = silhouette_score(freq, gmm_struc_pred, metric='sqeuclidean')\n",
    "    return [km_freq, km_freq_score], [km_struc, km_struc_score], [gmm_freq, gmm_freq_score], [gmm_struc, gmm_struc_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acts Scores:\n",
      "Frequency: gmm: 0.287220120083 km: 0.287220120083\n",
      "Structural: gmm: 0.207194553257 km: 0.329497252899\n",
      "Scenes Scores:\n",
      "Frequency: gmm: 0.210005008694 km: 0.210005008694\n",
      "Structural: gmm: 0.145588370851 km: 0.411959480389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\greeniend\\Anaconda\\envs\\py3k\\lib\\site-packages\\numpy\\core\\_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "km_acts_freq, km_acts_struc, gmm_acts_freq, gmm_acts_struc = authorship(shakespeare_acts, 3)\n",
    "km_scenes_freq, km_scenes_struc, gmm_scenes_freq, gmm_scenes_struc = authorship(shakespeare_scenes, 3)\n",
    "\n",
    "print (\"Acts Scores:\")\n",
    "print(\"Frequency: gmm:\", gmm_acts_freq[1], \"km:\", km_acts_freq[1])\n",
    "print(\"Structural: gmm:\", gmm_acts_struc[1], \"km:\", km_acts_struc[1])\n",
    "print (\"Scenes Scores:\")\n",
    "print(\"Frequency: gmm:\", gmm_scenes_freq[1], \"km:\", km_scenes_freq[1])\n",
    "print(\"Structural: gmm:\", gmm_scenes_struc[1], \"km:\", km_scenes_struc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Title Act  Frequency_km  Structural_km\n",
      "0       All's Well That Ends Well   1             1              0\n",
      "1       All's Well That Ends Well   2             1              1\n",
      "2       All's Well That Ends Well   3             1              1\n",
      "3       All's Well That Ends Well   4             1              1\n",
      "4       All's Well That Ends Well   5             1              1\n",
      "5                  As You Like It   1             1              1\n",
      "6                  As You Like It   2             0              0\n",
      "7                  As You Like It   3             1              1\n",
      "8                  As You Like It   4             1              1\n",
      "9                  As You Like It   5             1              0\n",
      "10           The Comedy of Errors   1             0              0\n",
      "11           The Comedy of Errors   2             1              1\n",
      "12           The Comedy of Errors   3             1              1\n",
      "13           The Comedy of Errors   4             1              1\n",
      "14           The Comedy of Errors   5             0              1\n",
      "15                      Cymbeline   1             1              1\n",
      "16                      Cymbeline   2             1              1\n",
      "17                      Cymbeline   3             1              1\n",
      "18                      Cymbeline   4             1              1\n",
      "19                      Cymbeline   5             0              0\n",
      "20             Loves Labours Lost   1             1              1\n",
      "21             Loves Labours Lost   2             1              1\n",
      "22             Loves Labours Lost   3             1              1\n",
      "23             Loves Labours Lost   4             1              1\n",
      "24             Loves Labours Lost   5             1              1\n",
      "25            Measure for Measure   1             1              1\n",
      "26            Measure for Measure   2             1              1\n",
      "27            Measure for Measure   3             1              1\n",
      "28            Measure for Measure   4             1              1\n",
      "29            Measure for Measure   5             1              1\n",
      "..                            ...  ..           ...            ...\n",
      "157                     King Lear   1             1              1\n",
      "158                     King Lear   2             1              1\n",
      "159                     King Lear   3             1              1\n",
      "160                     King Lear   4             1              1\n",
      "161                     King Lear   5             1              1\n",
      "162        The Tragedy of Macbeth   1             0              1\n",
      "163        The Tragedy of Macbeth   2             1              1\n",
      "164        The Tragedy of Macbeth   3             0              0\n",
      "165        The Tragedy of Macbeth   4             1              1\n",
      "166        The Tragedy of Macbeth   5             1              1\n",
      "167  Othello, the Moore of Venice   1             0              0\n",
      "168  Othello, the Moore of Venice   2             0              1\n",
      "169  Othello, the Moore of Venice   3             1              1\n",
      "170  Othello, the Moore of Venice   4             1              1\n",
      "171  Othello, the Moore of Venice   5             1              1\n",
      "172              Romeo and Juliet   1             1              1\n",
      "173              Romeo and Juliet   2             1              1\n",
      "174              Romeo and Juliet   3             1              0\n",
      "175              Romeo and Juliet   4             1              0\n",
      "176              Romeo and Juliet   5             0              1\n",
      "177               Timon of Athens   1             1              1\n",
      "178               Timon of Athens   2             1              1\n",
      "179               Timon of Athens   3             1              1\n",
      "180               Timon of Athens   4             0              1\n",
      "181               Timon of Athens   5             0              0\n",
      "182              Titus Andronicus   1             0              0\n",
      "183              Titus Andronicus   2             0              0\n",
      "184              Titus Andronicus   3             0              0\n",
      "185              Titus Andronicus   4             0              0\n",
      "186              Titus Andronicus   5             0              0\n",
      "\n",
      "[187 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['Title', 'Act', 'Frequency_km', 'Structural_km']\n",
    "clusters = pd.DataFrame(columns = columns)\n",
    "clusters['Title'] = [item['title'] for item in shakespeare_acts]\n",
    "clusters['Act'] = [item['act'] for item in shakespeare_acts]\n",
    "clusters['Frequency_km'] = km_acts_freq[0].labels_\n",
    "clusters['Structural_km'] = km_acts_struc[0].labels_\n",
    "print (clusters)\n",
    "clusters.to_csv('clusters_acts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Title Act  Frequency_km  Structural_km Scene\n",
      "0    All's Well That Ends Well   1             0              2     1\n",
      "1    All's Well That Ends Well   1             1              0     2\n",
      "2    All's Well That Ends Well   1             0              0     3\n",
      "3    All's Well That Ends Well   2             0              0     1\n",
      "4    All's Well That Ends Well   2             0              2     2\n",
      "5    All's Well That Ends Well   2             0              2     3\n",
      "6    All's Well That Ends Well   2             0              2     4\n",
      "7    All's Well That Ends Well   2             0              2     5\n",
      "8    All's Well That Ends Well   3             1              2     1\n",
      "9    All's Well That Ends Well   3             0              2     2\n",
      "10   All's Well That Ends Well   3             1              2     3\n",
      "11   All's Well That Ends Well   3             1              0     4\n",
      "12   All's Well That Ends Well   3             0              2     5\n",
      "13   All's Well That Ends Well   3             0              2     6\n",
      "14   All's Well That Ends Well   3             0              0     7\n",
      "15   All's Well That Ends Well   4             0              2     1\n",
      "16   All's Well That Ends Well   4             0              0     2\n",
      "17   All's Well That Ends Well   4             0              2     3\n",
      "18   All's Well That Ends Well   4             1              0     4\n",
      "19   All's Well That Ends Well   4             0              2     5\n",
      "20   All's Well That Ends Well   5             0              2     1\n",
      "21   All's Well That Ends Well   5             0              2     2\n",
      "22   All's Well That Ends Well   5             0              2     3\n",
      "23              As You Like It   1             0              0     1\n",
      "24              As You Like It   1             0              2     2\n",
      "25              As You Like It   1             0              2     3\n",
      "26              As You Like It   2             1              0     1\n",
      "27              As You Like It   2             1              0     2\n",
      "28              As You Like It   2             1              2     3\n",
      "29              As You Like It   2             0              2     4\n",
      "..                         ...  ..           ...            ...   ...\n",
      "723            Timon of Athens   1             0              2     2\n",
      "724            Timon of Athens   2             1              0     1\n",
      "725            Timon of Athens   2             0              2     2\n",
      "726            Timon of Athens   3             0              2     1\n",
      "727            Timon of Athens   3             0              2     2\n",
      "728            Timon of Athens   3             0              2     3\n",
      "729            Timon of Athens   3             0              2     4\n",
      "730            Timon of Athens   3             1              2     5\n",
      "731            Timon of Athens   3             0              2     6\n",
      "732            Timon of Athens   4             1              2     1\n",
      "733            Timon of Athens   4             0              2     2\n",
      "734            Timon of Athens   4             1              2     3\n",
      "735            Timon of Athens   5             0              2     1\n",
      "736            Timon of Athens   5             1              0     2\n",
      "737            Timon of Athens   5             0              2     3\n",
      "738            Timon of Athens   5             1              0     4\n",
      "739           Titus Andronicus   1             1              0     1\n",
      "740           Titus Andronicus   2             1              2     1\n",
      "741           Titus Andronicus   2             1              2     2\n",
      "742           Titus Andronicus   2             1              2     3\n",
      "743           Titus Andronicus   2             1              2     4\n",
      "744           Titus Andronicus   3             1              0     1\n",
      "745           Titus Andronicus   3             1              0     2\n",
      "746           Titus Andronicus   4             1              0     1\n",
      "747           Titus Andronicus   4             1              2     2\n",
      "748           Titus Andronicus   4             0              2     3\n",
      "749           Titus Andronicus   4             1              0     4\n",
      "750           Titus Andronicus   5             1              0     1\n",
      "751           Titus Andronicus   5             1              0     2\n",
      "752           Titus Andronicus   5             1              0     3\n",
      "\n",
      "[753 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['Title', 'Act', 'Frequency_km', 'Structural_km']\n",
    "clusters = pd.DataFrame(columns = columns)\n",
    "clusters['Title'] = [item['title'] for item in shakespeare_scenes]\n",
    "clusters['Act'] = [item['act'] for item in shakespeare_scenes]\n",
    "clusters['Scene'] = [item['scene'] for item in shakespeare_scenes]\n",
    "clusters['Frequency_km'] = km_scenes_freq[0].labels_\n",
    "clusters['Structural_km'] = km_scenes_struc[0].labels_\n",
    "print (clusters)\n",
    "clusters.to_csv('clusters_scenes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
